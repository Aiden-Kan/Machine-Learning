{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dedicated-campus",
   "metadata": {},
   "source": [
    "## 任务描述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-slave",
   "metadata": {},
   "source": [
    "1. 掌握Adaboost迭代过程\n",
    "\n",
    "2. 了解Adaboost参数和方法\n",
    "\n",
    "3. 掌握Adaboost调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-kingston",
   "metadata": {},
   "source": [
    "## 相关知识"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-income",
   "metadata": {},
   "source": [
    "Adaboost实现的迭代过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-equity",
   "metadata": {},
   "source": [
    "(1)利用buildStump()函数找到最佳的单层决策树；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-disclosure",
   "metadata": {},
   "source": [
    "(2)将最佳单层决策树加入到单层决策树数组；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-twins",
   "metadata": {},
   "source": [
    "(3)计算Alpha；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-terrorist",
   "metadata": {},
   "source": [
    "(4)计算新的权重向量D；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-exclusive",
   "metadata": {},
   "source": [
    "(5)更新累计类别估计值；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-sleeping",
   "metadata": {},
   "source": [
    "(6)如果错误率为等于0.0，退出循环。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-interview",
   "metadata": {},
   "source": [
    "本节我们使用Adaboost算法来实现马疝病的检测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-diploma",
   "metadata": {},
   "source": [
    "马疝病不一定源自马的肠胃问题，其他问题也可能引发马疝病。本次使用的数据集中包含了医院检测马疝病的一些特征，有的指标比较主观，有些指标难以测量，例如马的疼痛级别。另外，除了部分指标主观和难以测量之外，该数据还存在30%的数据缺失问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-denmark",
   "metadata": {},
   "source": [
    "面对数据集中数据缺失问题，我们可以采用数据预处理\n",
    "\n",
    "1.如果测试集中的一条数据的特征值已经确实，那么可以选择实数0来替代所有缺失值。\n",
    "\n",
    "2.如果测试集中一条数据的类别标签已经缺失，那么将该类别数据丢弃。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-jamaica",
   "metadata": {},
   "source": [
    "接下来我们了解一下Sklearn中Adaboost模型\n",
    "\n",
    "class sklearn.ensemble.AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-device",
   "metadata": {},
   "source": [
    "**Adaboost-参数**\n",
    "\n",
    "base_estimator:基分类器，默认是决策树，在该分类器基础上进行boosting，理论上可以是任意一个分类器，但是如果是其他分类器时需要指明样本权重。\n",
    "\n",
    "n_estimators:基分类器提升（循环）次数，默认是50次，这个值过大，模型容易过拟合；值过小，模型容易欠拟合。\n",
    "\n",
    "learning_rate:学习率，表示梯度收敛速度，默认为1，如果过大，容易错过最优值，如果过小，则收敛速度会很慢；该值需要和n_estimators进行一个权衡，当分类器迭代次数较少时，学习率可以小一些，当迭代次数较多时，学习率可以适当放大。\n",
    "\n",
    "algorithm:boosting算法，也就是模型提升准则，有两种方式SAMME, 和SAMME.R两种，默认是SAMME.R，两者的区别主要是弱学习器权重的度量，前者是对样本集预测错误的概率进行划分的，后者是对样本集的预测错误的比例，即错分率进行划分的，默认是用的SAMME.R。\n",
    "\n",
    "random_state:随机种子设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-friday",
   "metadata": {},
   "source": [
    "关于Adaboost模型本身的参数并不多，但是我们在实际中除了调整Adaboost模型参数外，还可以调整基分类器的参数，关于基分类的调参，和单模型的调参是完全一样的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-scanning",
   "metadata": {},
   "source": [
    "**Adaboost-常用方法**\n",
    "\n",
    "fit(X,Y):在数据集（X,Y）上训练模型。\n",
    "\n",
    "predict(X):预测数据集X的结果。\n",
    "\n",
    "score(X,Y):输出数据集（X,Y）在模型上的准确率。\n",
    "\n",
    "staged_predict(X):返回每个基分类器的预测数据集X的结果。\n",
    "\n",
    "staged_score(X, Y):返回每个基分类器的预测准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "express-funds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8059701492537313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path, sep='\\t', names=[i for i in range(22)])\n",
    "    data = np.array(data).tolist()\n",
    "    x = []; y = []\n",
    "    for i in range(len(data)):\n",
    "        y.append(data[i][-1])\n",
    "        del data[i][-1]\n",
    "        x.append(data[i])\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def AdaBoost():\n",
    "    train_x, train_y = load_data('../../data/3.15/horseColicTraining2.txt')\n",
    "    test_x, test_y = load_data('../../data/3.15/horseColicTest2.txt')\n",
    "    #训练\n",
    "    clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7, min_samples_leaf=7), n_estimators=100, algorithm='SAMME', learning_rate=0.95)\n",
    "    clf.fit(train_x, train_y)\n",
    "    #测试\n",
    "    print(clf.score(test_x, test_y))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    AdaBoost()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-peeing",
   "metadata": {},
   "source": [
    "## 编程要求"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-penguin",
   "metadata": {},
   "source": [
    "复习上述内容，利用上述代码尝试Adaboost调参，从而观察数据集在训练模型上的准确率变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-cricket",
   "metadata": {},
   "source": [
    "## 参考答案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-account",
   "metadata": {},
   "source": [
    "略"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
