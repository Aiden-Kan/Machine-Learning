{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "shared-library",
   "metadata": {},
   "source": [
    "## 任务描述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-marijuana",
   "metadata": {},
   "source": [
    "1. 了解随机森林基本概念\n",
    "\n",
    "2. 了解OOB误分率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-princess",
   "metadata": {},
   "source": [
    "## 相关知识"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-divorce",
   "metadata": {},
   "source": [
    "![jupyter](https://i.loli.net/2021/06/02/IB65VsZK2d7zCt8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-crest",
   "metadata": {},
   "source": [
    "随机森林（Random forest，简称RF），在之前集成方法中我们主要了解了Bagging和Boosting两种方法，而随机森林则是属于Bagging方法，采用自举汇聚法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-party",
   "metadata": {},
   "source": [
    "随机森林就是通过集成学习的思想将多棵树集成的一种算法，它的基本单元是决策树，随机森林就是在随机子空间中随机组合的自由生长的CART决策树+Bagging得到的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-still",
   "metadata": {},
   "source": [
    "随机森林的名称中有两个关键词，一个是“随机”，一个就是“森林”。“森林”我们很好理解，一棵叫做树，那么成百上千棵就可以叫做森林了。“随机”是指数据随机采样以及特征随机采样，主要体现在Bagging，它的全称是Bootstrap aggregation，称为自助法，它是一种有放回的抽样方法。Bagging的每个弱学习器的训练集都是通过随机且有放回采样得到的，简单来说就是每次从原始样本中随机且有放回的采样n个训练样本，进行T轮采样，得到T个训练集，然后用这T个训练集，分别独立训练T个弱学习器，这T个弱学习器结合成一个强学习器，强学习器的结果作为整体的结果输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-humanity",
   "metadata": {},
   "source": [
    "**随机森林的特点**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-consultancy",
   "metadata": {},
   "source": [
    "1.在当前所有算法中，具有极好的准确率\n",
    "\n",
    "2.能够有效地运行在大数据集上\n",
    "\n",
    "3.能够处理具有高维特征的输入样本，而且不需要降维\n",
    "\n",
    "4.能够评估各个特征在分类问题上的重要性\n",
    "\n",
    "5.在生成过程中，能够获取到内部生成误差的一种无偏估计\n",
    "\n",
    "6.对于缺省值问题也能够获得很好得结果\n",
    "\n",
    "... ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-nomination",
   "metadata": {},
   "source": [
    "实际上，随机森林的特点不只有这六点，它就相当于机器学习领域的Leatherman（多面手），你几乎可以把任何东西扔进去，它基本上都是可供使用的。在估计推断映射方面特别好用，以致都不需要像SVM那样做很多参数的调试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-yahoo",
   "metadata": {},
   "source": [
    "**随机森林的生成**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-warrant",
   "metadata": {},
   "source": [
    "每棵树的按照如下规则生成：\n",
    "\n",
    "1）如果训练集大小为N，对于每棵树而言，随机且有放回地从训练集中的抽取N个训练样本（这种采样方式称为bootstrap sample方法），作为该树的训练集；\n",
    "\n",
    "从这里我们可以知道：每棵树的训练集都是不同的，而且里面包含重复的训练样本（理解这点很重要）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-fountain",
   "metadata": {},
   "source": [
    "随机森林分类效果（错误率）与两个因素有关："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-aquatic",
   "metadata": {},
   "source": [
    "1.森林中任意两棵树的相关性：相关性越大，错误率越大；\n",
    "\n",
    "2.森林中每棵树的分类能力：每棵树的分类能力越强，整个森林的错误率越低。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-ensemble",
   "metadata": {},
   "source": [
    "减小特征选择个数m，树的相关性和分类能力也会相应的降低；增大m，两者也会随之增大。所以关键问题是如何选择最优的m（或者是范围），这也是随机森林唯一的一个参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-basketball",
   "metadata": {},
   "source": [
    "**袋外错误率（oob error）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-pantyhose",
   "metadata": {},
   "source": [
    "上面我们提到，构建随机森林的关键问题就是如何选择最优的m，要解决这个问题主要依据计算袋外错误率oob error（out-of-bag error）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-strap",
   "metadata": {},
   "source": [
    "在构建每棵树时，我们对训练集使用了不同的bootstrap sample（随机且有放回地抽取）。所以对于每棵树而言（假设对于第k棵树），大约有1/3的训练实例没有参与第k棵树的生成，它们称为第k棵树的oob样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-victoria",
   "metadata": {},
   "source": [
    "而这样的采样特点就允许我们进行oob估计，它的计算方式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-footage",
   "metadata": {},
   "source": [
    "（note：以样本为单位）\n",
    "\n",
    "1）对每个样本，计算它作为oob样本的树对它的分类情况（约1/3的树）；\n",
    "\n",
    "2）然后以简单多数投票作为该样本的分类结果；\n",
    "\n",
    "3）最后用误分个数占样本总数的比率作为随机森林的oob误分率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-hampshire",
   "metadata": {},
   "source": [
    "oob误分率是随机森林泛化误差的一个无偏估计，它的结果近似于需要大量计算的k折交叉验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-links",
   "metadata": {},
   "source": [
    "## 编程要求"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-messenger",
   "metadata": {},
   "source": [
    "略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-today",
   "metadata": {},
   "source": [
    "## 实战练习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-collector",
   "metadata": {},
   "source": [
    "1.以下关于随机森林的描述，不正确的是（ ） (单选)\n",
    "\n",
    "A. 随机森林的起始性能一般较差\n",
    "\n",
    "B. 随机森林的训练效率常优于Bagging\n",
    "\n",
    "C. 在随机森林中，对于基决策树中的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，然后从这个子集中选择一个最优属性用于划分。当k=1时，基决策树的构建与传统决策树相同。\n",
    "\n",
    "D. 随机森林基学习器的“多样性”不仅来自样本扰动，还来自属性扰动。\n",
    "\n",
    "2.关于随机森林描述不正确的是 (    )    (单选)\n",
    "\n",
    "A. 随机森林是一种集成学习算法\n",
    "\n",
    "B. 随机森林的随机性主要体现在训练单决策树时，对样本和特征同时进行采样\n",
    "\n",
    "C. 随机森林算法可以高度并行化\n",
    "\n",
    "D. 随机森林预测时，根据单决策树分类误差进行加权投票"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-boring",
   "metadata": {},
   "source": [
    "## 参考答案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-dealing",
   "metadata": {},
   "source": [
    "1. C\n",
    "\n",
    "2. D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
