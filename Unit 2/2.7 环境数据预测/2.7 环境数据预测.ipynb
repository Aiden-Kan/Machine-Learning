{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.掌握逻辑回归的基本概念。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.运用逻辑回归解决实际问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相关知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**逻辑回归**也被称为广义线性回归模型，它与线性回归模型的形式基本上相同，最大的区别在于它们的因变量不同，如果是连续的，就是多重线性回归；如果是二项分布，就是Logistic回归。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归的**用途**主要有以下3个方面："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.寻找危险因素；寻找某一疾病的危险因素等；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.预测：根据模型，预测在不同的自变量情况下，发生某种疾病或某种情况的概率有多大；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.判别：实际上跟预测有些类似，也是根据模型，判断某人属于某种疾病或属于某种情况的概率有多大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**逻辑回归的常规步骤**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.寻找$h$函数（即预测函数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.构造$J$函数（损失函数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.想办法使得$J$函数最小并求得回归参数（$θ$）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们通过**环境数据检测异常分析与预测**这个实验，对逻辑回归进行具体的实现及应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -0.017612   14.053064   0\n",
      "0   -1.395634   4.662541    1\n",
      "1   -0.752157   6.538620    0\n",
      "2   -1.322371   7.152853    0\n",
      "3   0.423363    11.054677   0\n",
      "4   0.406704    7.067335    1\n",
      "..                        ...\n",
      "94  0.677983    2.556666    1\n",
      "95  0.761349    10.693862   0\n",
      "96  -2.168791   0.143632    1\n",
      "97  1.388610    9.341997    0\n",
      "98  0.317029    14.739025   0\n",
      "\n",
      "[99 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[1.0, -0.017612, 14.053064],\n",
       "  [1.0, -1.395634, 4.662541],\n",
       "  [1.0, -0.752157, 6.53862],\n",
       "  [1.0, -1.322371, 7.152853],\n",
       "  [1.0, 0.423363, 11.054677],\n",
       "  [1.0, 0.406704, 7.067335],\n",
       "  [1.0, 0.667394, 12.741452],\n",
       "  [1.0, -2.46015, 6.866805],\n",
       "  [1.0, 0.569411, 9.548755],\n",
       "  [1.0, -0.026632, 10.427743],\n",
       "  [1.0, 0.850433, 6.920334],\n",
       "  [1.0, 1.347183, 13.1755],\n",
       "  [1.0, 1.176813, 3.16702],\n",
       "  [1.0, -1.781871, 9.097953],\n",
       "  [1.0, -0.566606, 5.749003],\n",
       "  [1.0, 0.931635, 1.589505],\n",
       "  [1.0, -0.024205, 6.151823],\n",
       "  [1.0, -0.036453, 2.690988],\n",
       "  [1.0, -0.196949, 0.444165],\n",
       "  [1.0, 1.014459, 5.754399],\n",
       "  [1.0, 1.985298, 3.230619],\n",
       "  [1.0, -1.693453, -0.55754],\n",
       "  [1.0, -0.576525, 11.778922],\n",
       "  [1.0, -0.346811, -1.67873],\n",
       "  [1.0, -2.124484, 2.672471],\n",
       "  [1.0, 1.217916, 9.597015],\n",
       "  [1.0, -0.733928, 9.098687],\n",
       "  [1.0, -3.642001, -1.618087],\n",
       "  [1.0, 0.315985, 3.523953],\n",
       "  [1.0, 1.416614, 9.619232],\n",
       "  [1.0, -0.386323, 3.989286],\n",
       "  [1.0, 0.556921, 8.294984],\n",
       "  [1.0, 1.224863, 11.58736],\n",
       "  [1.0, -1.347803, -2.406051],\n",
       "  [1.0, 1.196604, 4.951851],\n",
       "  [1.0, 0.275221, 9.543647],\n",
       "  [1.0, 0.470575, 9.332488],\n",
       "  [1.0, -1.889567, 9.542662],\n",
       "  [1.0, -1.527893, 12.150579],\n",
       "  [1.0, -1.185247, 11.309318],\n",
       "  [1.0, -0.445678, 3.297303],\n",
       "  [1.0, 1.042222, 6.105155],\n",
       "  [1.0, -0.618787, 10.320986],\n",
       "  [1.0, 1.152083, 0.548467],\n",
       "  [1.0, 0.828534, 2.676045],\n",
       "  [1.0, -1.237728, 10.549033],\n",
       "  [1.0, -0.683565, -2.166125],\n",
       "  [1.0, 0.229456, 5.921938],\n",
       "  [1.0, -0.959885, 11.555336],\n",
       "  [1.0, 0.492911, 10.993324],\n",
       "  [1.0, 0.184992, 8.721488],\n",
       "  [1.0, -0.355715, 10.325976],\n",
       "  [1.0, -0.397822, 8.058397],\n",
       "  [1.0, 0.824839, 13.730343],\n",
       "  [1.0, 1.507278, 5.027866],\n",
       "  [1.0, 0.099671, 6.835839],\n",
       "  [1.0, -0.344008, 10.717485],\n",
       "  [1.0, 1.785928, 7.718645],\n",
       "  [1.0, -0.918801, 11.560217],\n",
       "  [1.0, -0.364009, 4.7473],\n",
       "  [1.0, -0.841722, 4.119083],\n",
       "  [1.0, 0.490426, 1.960539],\n",
       "  [1.0, -0.007194, 9.075792],\n",
       "  [1.0, 0.356107, 12.447863],\n",
       "  [1.0, 0.342578, 12.281162],\n",
       "  [1.0, -0.810823, -1.466018],\n",
       "  [1.0, 2.530777, 6.476801],\n",
       "  [1.0, 1.296683, 11.607559],\n",
       "  [1.0, 0.475487, 12.040035],\n",
       "  [1.0, -0.783277, 11.009725],\n",
       "  [1.0, 0.074798, 11.02365],\n",
       "  [1.0, -1.337472, 0.468339],\n",
       "  [1.0, -0.102781, 13.763651],\n",
       "  [1.0, -0.147324, 2.874846],\n",
       "  [1.0, 0.518389, 9.887035],\n",
       "  [1.0, 1.015399, 7.571882],\n",
       "  [1.0, -1.658086, -0.027255],\n",
       "  [1.0, 1.319944, 2.171228],\n",
       "  [1.0, 2.056216, 5.019981],\n",
       "  [1.0, -0.851633, 4.375691],\n",
       "  [1.0, -1.510047, 6.061992],\n",
       "  [1.0, -1.076637, -3.181888],\n",
       "  [1.0, 1.821096, 10.28399],\n",
       "  [1.0, 3.01015, 8.401766],\n",
       "  [1.0, -1.099458, 1.688274],\n",
       "  [1.0, -0.834872, -1.733869],\n",
       "  [1.0, -0.846637, 3.849075],\n",
       "  [1.0, 1.400102, 12.628781],\n",
       "  [1.0, 1.752842, 5.468166],\n",
       "  [1.0, 0.078557, 0.059736],\n",
       "  [1.0, 0.089392, -0.7153],\n",
       "  [1.0, 1.825662, 12.693808],\n",
       "  [1.0, 0.197445, 9.744638],\n",
       "  [1.0, 0.126117, 0.922311],\n",
       "  [1.0, -0.679797, 1.22053],\n",
       "  [1.0, 0.677983, 2.556666],\n",
       "  [1.0, 0.761349, 10.693862],\n",
       "  [1.0, -2.168791, 0.143632],\n",
       "  [1.0, 1.38861, 9.341997],\n",
       "  [1.0, 0.317029, 14.739025]],\n",
       " [0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import *\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "filename='./data.txt' #文件目录\n",
    "#df = DataFrame(pd.read_csv('/Users/apple27/Documents/logi.csv'))\n",
    "def loadDataSet():   #读取数据（这里只有两个特征）\n",
    "    df=pd.read_csv(filename)\n",
    "    print(df)\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(filename)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split()\n",
    "        dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])  #前面的1，表示方程的常量。比如两个特征X1,X2，共需要三个参数，W1+W2*X1+W3*X2\n",
    "        labelMat.append(int(lineArr[2]))\n",
    "    return dataMat,labelMat\n",
    "loadDataSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(inX):  #sigmoid函数\n",
    "    return 1.0/(1+exp(-inX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改进版随机梯度上升，在每次迭代中随机选择样本来更新权重，并且随迭代次数增加，，权重变化越小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stocGradAscent1(dataMat, labelMat): #改进版随机梯度上升，在每次迭代中随机选择样本来更新权重，并且随迭代次数增加，权重变化越小。\n",
    "    dataMatrix=mat(dataMat)\n",
    "    classLabels=labelMat\n",
    "    m,n=shape(dataMatrix)\n",
    "    weights=ones((n,1))\n",
    "    maxCycles=500\n",
    "    for j in range(maxCycles): #迭代\n",
    "        dataIndex=[i for i in range(m)]\n",
    "        for i in range(m): #随机遍历每一行\n",
    "            alpha=4/(1+j+i)+0.0001  #随迭代次数增加，权重变化越小。\n",
    "            randIndex=int(random.uniform(0,len(dataIndex)))  #随机抽样\n",
    "            h=sigmoid(sum(dataMatrix[randIndex]*weights))\n",
    "            error=classLabels[randIndex]-h\n",
    "            weights=weights+alpha*error*dataMatrix[randIndex].transpose()\n",
    "            del(dataIndex[randIndex]) #去除已经抽取的样本\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画出最终分类的图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -0.017612   14.053064   0\n",
      "0   -1.395634   4.662541    1\n",
      "1   -0.752157   6.538620    0\n",
      "2   -1.322371   7.152853    0\n",
      "3   0.423363    11.054677   0\n",
      "4   0.406704    7.067335    1\n",
      "..                        ...\n",
      "94  0.677983    2.556666    1\n",
      "95  0.761349    10.693862   0\n",
      "96  -2.168791   0.143632    1\n",
      "97  1.388610    9.341997    0\n",
      "98  0.317029    14.739025   0\n",
      "\n",
      "[99 rows x 1 columns]\n",
      "    -0.017612   14.053064   0\n",
      "0   -1.395634   4.662541    1\n",
      "1   -0.752157   6.538620    0\n",
      "2   -1.322371   7.152853    0\n",
      "3   0.423363    11.054677   0\n",
      "4   0.406704    7.067335    1\n",
      "..                        ...\n",
      "94  0.677983    2.556666    1\n",
      "95  0.761349    10.693862   0\n",
      "96  -2.168791   0.143632    1\n",
      "97  1.388610    9.341997    0\n",
      "98  0.317029    14.739025   0\n",
      "\n",
      "[99 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotBestFit(weights):  #画出最终分类的图\n",
    "    import matplotlib.pyplot as plt\n",
    "    dataMat,labelMat=loadDataSet()\n",
    "    dataArr = array(dataMat)\n",
    "    n = shape(dataArr)[0]\n",
    "    xcord1 = []; ycord1 = []\n",
    "    xcord2 = []; ycord2 = []\n",
    "    for i in range(n):\n",
    "        if int(labelMat[i])== 1:\n",
    "            xcord1.append(dataArr[i,1])\n",
    "            ycord1.append(dataArr[i,2])\n",
    "        else:\n",
    "            xcord2.append(dataArr[i,1])\n",
    "            ycord2.append(dataArr[i,2])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(xcord1, ycord1, s=30, c='red', marker='s')\n",
    "    ax.scatter(xcord2, ycord2, s=30, c='green')\n",
    "    x = arange(-3.0, 3.0, 0.1)\n",
    "    y = (-weights[0]-weights[1]*x)/weights[2]\n",
    "    ax.plot(x, y)\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.show()\n",
    "    plt.savefig('logExample.png', format='png')\n",
    "def main():\n",
    "    datamat,labelmat=loadDataSet()\n",
    "    weights=stocGradAscent1(datamat, labelmat).getA()\n",
    "    plotBestFit(weights)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程要求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "复习逻辑回归的基本原理与概念，编程实现基于逻辑回归的环境检测数据异常分析与预测实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "filename='./data.txt' #文件目录\n",
    "#df = DataFrame(pd.read_csv('/Users/apple27/Documents/logi.csv'))\n",
    "def loadDataSet():   #读取数据（这里只有两个特征）\n",
    "    df=pd.read_csv(filename)\n",
    "    print(df)\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(filename)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split()\n",
    "        dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])  #前面的1，表示方程的常量。比如两个特征X1,X2，共需要三个参数，W1+W2*X1+W3*X2\n",
    "        labelMat.append(int(lineArr[2]))\n",
    "    return dataMat,labelMat\n",
    "\n",
    "loadDataSet()\n",
    "def sigmoid(inX):  #sigmoid函数\n",
    "    return 1.0/(1+exp(-inX))\n",
    "\n",
    "def stocGradAscent1(dataMat, labelMat): #改进版随机梯度上升，在每次迭代中随机选择样本来更新权重，并且随迭代次数增加，权重变化越小。\n",
    "    dataMatrix=mat(dataMat)\n",
    "    classLabels=labelMat\n",
    "    m,n=shape(dataMatrix)\n",
    "    weights=ones((n,1))\n",
    "    maxCycles=500\n",
    "    for j in range(maxCycles): #迭代\n",
    "        dataIndex=[i for i in range(m)]\n",
    "        for i in range(m): #随机遍历每一行\n",
    "            alpha=4/(1+j+i)+0.0001  #随迭代次数增加，权重变化越小。\n",
    "            randIndex=int(random.uniform(0,len(dataIndex)))  #随机抽样\n",
    "            h=sigmoid(sum(dataMatrix[randIndex]*weights))\n",
    "            error=classLabels[randIndex]-h\n",
    "            weights=weights+alpha*error*dataMatrix[randIndex].transpose()\n",
    "            del(dataIndex[randIndex]) #去除已经抽取的样本\n",
    "    return weights\n",
    "\n",
    "def plotBestFit(weights):  #画出最终分类的图\n",
    "    import matplotlib.pyplot as plt\n",
    "    dataMat,labelMat=loadDataSet()\n",
    "    dataArr = array(dataMat)\n",
    "    n = shape(dataArr)[0]\n",
    "    xcord1 = []; ycord1 = []\n",
    "    xcord2 = []; ycord2 = []\n",
    "    for i in range(n):\n",
    "        if int(labelMat[i])== 1:\n",
    "            xcord1.append(dataArr[i,1])\n",
    "            ycord1.append(dataArr[i,2])\n",
    "        else:\n",
    "            xcord2.append(dataArr[i,1])\n",
    "            ycord2.append(dataArr[i,2])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(xcord1, ycord1, s=30, c='red', marker='s')\n",
    "    ax.scatter(xcord2, ycord2, s=30, c='green')\n",
    "    x = arange(-3.0, 3.0, 0.1)\n",
    "    y = (-weights[0]-weights[1]*x)/weights[2]\n",
    "    ax.plot(x, y)\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.show()\n",
    "    plt.savefig('logExample.png', format='png')\n",
    "def main():\n",
    "    datamat,labelmat=loadDataSet()\n",
    "    weights=stocGradAscent1(datamat, labelmat).getA()\n",
    "    plotBestFit(weights)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1.0 / (1 + exp(-X))\n",
    "\n",
    "\n",
    "class logRegressClassifier(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dataMat = list()\n",
    "        self.labelMat = list()\n",
    "        self.weights = list()\n",
    "\n",
    "    def loadDataSet(self, filename):\n",
    "        fr = open(filename)\n",
    "        for line in fr.readlines():\n",
    "            lineArr = line.strip().split()\n",
    "            dataLine = [1.0]\n",
    "            for i in lineArr:\n",
    "                dataLine.append(float(i))\n",
    "            label = dataLine.pop()  # pop the last column referring to  label\n",
    "            self.dataMat.append(dataLine)\n",
    "            self.labelMat.append(int(label))\n",
    "        self.dataMat = mat(self.dataMat)\n",
    "        self.labelMat = mat(self.labelMat).transpose()\n",
    "\n",
    "    def train(self):\n",
    "        self.weights = self.stocGradAscent1()\n",
    "\n",
    "    def batchGradAscent(self):\n",
    "        m, n = shape(self.dataMat)\n",
    "        alpha = 0.001\n",
    "        maxCycles = 500\n",
    "        weights = ones((n, 1))\n",
    "        for k in range(maxCycles):  # heavy on matrix operations\n",
    "            h = sigmoid(self.dataMat * weights)  # matrix mult\n",
    "            error = (self.labelMat - h)  # vector subtraction\n",
    "            weights += alpha * self.dataMat.transpose() * error  # matrix mult\n",
    "        return weights\n",
    "\n",
    "    def stocGradAscent1(self):\n",
    "        m, n = shape(self.dataMat)\n",
    "        alpha = 0.01\n",
    "        weights = ones((n, 1))  # initialize to all ones\n",
    "        for i in range(m):\n",
    "            h = sigmoid(sum(self.dataMat[i] * weights))\n",
    "            error = self.labelMat[i] - h\n",
    "            weights += (alpha * error * self.dataMat[i]).transpose()\n",
    "        return weights\n",
    "\n",
    "    def stocGradAscent2(self):\n",
    "        numIter = 2\n",
    "        m, n = shape(self.dataMat)\n",
    "        weights = ones((n, 1))  # initialize to all ones\n",
    "        for j in range(numIter):\n",
    "            dataIndex = range(m)\n",
    "            for i in range(m):\n",
    "                alpha = 4 / (1.0 + j + i) + 0.0001  # apha decreases with iteration, does not\n",
    "                randIndex = int(random.uniform(0, len(dataIndex)))  # go to 0 because of the constant\n",
    "                h = sigmoid(sum(self.dataMat[randIndex] * weights))\n",
    "                error = self.labelMat[randIndex] - h\n",
    "                weights += (alpha * error * self.dataMat[randIndex]).transpose()\n",
    "                del (dataIndex[randIndex])\n",
    "        return weights\n",
    "\n",
    "    def classify(self, X):\n",
    "        prob = sigmoid(sum(X * self.weights))\n",
    "        if prob > 0.5:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lr = logRegressClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
